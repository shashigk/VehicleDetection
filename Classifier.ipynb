{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> code {background-color : pink !important;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style> code {background-color : pink !important;} </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Vehicle Detection using SVMs\n",
    "===\n",
    "\n",
    "### Vehicle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from default_params import *\n",
    "from utils import *\n",
    "from feature_ex import *\n",
    "from heat import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cars size = 8792\n",
      "Not Cars size = 8968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector size cars = (8792, 8460)\n",
      "Feature vector size notcars = (8968, 8460)\n"
     ]
    }
   ],
   "source": [
    "#Read image data-set.\n",
    "# Divide up into cars and notcars\n",
    "# Read in car and non-car images\n",
    "def image_file_names (glob_pattern) :\n",
    "    images = glob.glob (glob_pattern)\n",
    "    imagelist = []\n",
    "    for image in images:\n",
    "        imagelist.append(image)\n",
    "    return imagelist\n",
    "\n",
    "\n",
    "cars = []\n",
    "cars = image_file_names ('../data/vehicles/*/*.png')\n",
    "notcars = []\n",
    "notcars = image_file_names ('../data/non-vehicles/*/*.png')\n",
    "\n",
    "#print (\"Cars = {}\".format(cars[0:5]))\n",
    "print (\"Cars size = {}\".format(len (cars)))\n",
    "print (\"Not Cars size = {}\".format(len (notcars)))\n",
    "\n",
    "\n",
    "car_features = extract_features (cars)\n",
    "notcar_features = extract_features (notcars)\n",
    "if (np.shape (car_features[0]) != np.shape (notcar_features[0])) :\n",
    "    raise 'ERROR: HOG feature vector shapes for cars and not cars is different'\n",
    "if (np.shape (car_features[0]) != np.shape (notcar_features[0])) :\n",
    "    raise 'ERROR: COLOR feature vector shapes for cars and not cars is different'\n",
    "print (\"Feature vector size cars = {}\".format (np.shape (car_features)))\n",
    "print (\"Feature vector size notcars = {}\".format (np.shape (notcar_features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector size cars = (8792, 8460)\n",
      "Feature vector size notcars = (8968, 8460)\n"
     ]
    }
   ],
   "source": [
    "from moredata import *\n",
    "\n",
    "def useMoreData ():\n",
    "    morecars, morecarbbs, morenotcars, morenotcarbbs = LoadExtraData ()\n",
    "    morecar_feats = extract_features_from_frames (morecars, morecarbbs)\n",
    "    morenotcar_feats = extract_features_from_frames (morenotcars, morenotcarbbs)\n",
    "    ## Add features from the udacity dataset\n",
    "    car_features = car_features + morecar_feats\n",
    "    notcar_features = notcar_features + morenotcar_feats\n",
    "    return\n",
    "\n",
    "# \n",
    "# useMoreData ()\n",
    "if (np.shape (car_features[0]) != np.shape (notcar_features[0])) :\n",
    "    raise 'ERROR: HOG feature vector shapes for cars and not cars is different'\n",
    "if (np.shape (car_features[0]) != np.shape (notcar_features[0])) :\n",
    "    raise 'ERROR: COLOR feature vector shapes for cars and not cars is different'\n",
    "print (\"Feature vector size cars = {}\".format (np.shape (car_features)))\n",
    "print (\"Feature vector size notcars = {}\".format (np.shape (notcar_features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_hog_features Min = 0.0, Max = 4096.0\n",
      "notcar_hog_features Min = 0.0, Max = 4096.0\n"
     ]
    }
   ],
   "source": [
    "# Data set exploration\n",
    "def print_min_max (feature_set, name=None) :\n",
    "    if name == None :\n",
    "        name =\"\"\n",
    "    print (\"{} Min = {}, Max = {}\".format (name, np.min (feature_set), np.max(feature_set)))\n",
    "print_min_max (car_features, \"car_hog_features\")\n",
    "print_min_max (notcar_features, \"notcar_hog_features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features shape X = (17760, 8460), shape y = (17760,)\n",
      "All Features Min = 0.0, Max = 4096.0\n",
      "Normalized Feature vector size = (17760, 8460)\n",
      "Normalized Features Min = -14.155976671742794, Max = 102.58802116003011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def combine_features (car_features, notcar_features) :\n",
    "    num_carfeat = len (car_features)\n",
    "    num_notcarfeat = len (notcar_features)\n",
    "    X = np.vstack ((car_features, notcar_features)).astype(np.float64)\n",
    "    y = np.hstack ((np.ones (num_carfeat), np.zeros (num_notcarfeat)))\n",
    "    print (\"All features shape X = {}, shape y = {}\".format (np.shape(X), np.shape(y)))\n",
    "    print_min_max (X, \"All Features\")    \n",
    "    return X, y, num_carfeat, num_notcarfeat\n",
    "\n",
    "\n",
    "#car_features = select_random_subset (SUBSET_SIZE, car_features)\n",
    "#notcar_features = select_random_subset (SUBSET_SIZE, notcar_features)\n",
    "#print (\"Cars subset size = {}\".format(np.shape (car_features)))\n",
    "#print (\"Not Cars subset size = {}\".format(np.shape (notcars_features)))\n",
    "\n",
    "X, y, ncf, nnf = combine_features (car_features, notcar_features)\n",
    "#SUBSET_SIZE = 1000\n",
    "#X, y = select_random_subset_data (SUBSET_SIZE, X, y)\n",
    "\n",
    "def normalize_data (X) :\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    return scaled_X, X_scaler\n",
    "\n",
    "X, X_scaler = normalize_data (X)\n",
    "\n",
    "print (\"Normalized Feature vector size = {}\".format (np.shape (X)))\n",
    "print_min_max (X, \"Normalized Features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 9 orientations 8 pixels per cell and 2 cells per block\n",
      "Using spatial binning of: (32, 32) and 32 histogram bins\n",
      "Feature vector length: 8460\n",
      "21.1 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.991\n",
      "My SVC predicts:  [ 0.  1.  1.  1.  0.  1.  0.  1.  1.  0.]\n",
      "For these 10 labels:  [ 0.  1.  1.  1.  0.  1.  0.  1.  1.  0.]\n",
      "0.00459 Seconds to predict 10 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=rand_state)\n",
    "    \n",
    "print('Using:',DEFAULT_ORIENT,'orientations',DEFAULT_PIX_PER_CELL,\n",
    "    'pixels per cell and', DEFAULT_CELL_PER_BLOCK,'cells per block')\n",
    "\n",
    "print('Using spatial binning of:',DEFAULT_SPATIAL_SIZE,\n",
    "    'and', DEFAULT_HIST_BIN,'histogram bins')\n",
    "\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save model, scaler\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "VEHICLE_MODEL_PKL='vehicle_model.pkl'\n",
    "VEHICLE_SCALER_PKL='vehicle_scaler.pkl'\n",
    "def rm_models_scaler () :\n",
    "    try :\n",
    "        for f in glob.glob(VEHICLE_MODEL_PKL) :\n",
    "            os.remove (f)\n",
    "            print (\"Removed {}\".format(f))\n",
    "        for f in glob.glob (VEHICLE_SCALER_PKL) :\n",
    "            os.remove (f)\n",
    "            print (\"Removed {}\".format (f))\n",
    "    except :\n",
    "        print (\"Unable to remove existing models\")\n",
    "def save_models_scaler (svc, scaler) :\n",
    "    rm_models_scaler () # Remove existing models, scaler\n",
    "    joblib.dump (svc, VEHICLE_MODEL_PKL)\n",
    "    joblib.dump (scaler, VEHICLE_SCALER_PKL)\n",
    "def load_models_scaler () :\n",
    "    return joblib.load (VEHICLE_MODEL_PKL), joblib.load (VEHICLE_SCALER_PKL)\n",
    "\n",
    "save_models_scaler (svc, X_scaler)\n",
    "\n",
    "# To use saved models, uncomment the following line\n",
    "svc, X_scaler = load_models_scaler()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
